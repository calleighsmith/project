---
title: "Project Introduction: Analyzing U.S. Beaches"
author: "Calleigh Smith"
date: "Due 3/2/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=F, warning=F)
library(MASS)
library(tidyverse)
library(splitstackshape)
library(janitor)
library(gganimate)
library(gifski)
library(viridis)
library(patchwork)
library(magick)
library(AER)
library(DHARMa)
library(vcd)
library(pscl)
```

```{r, message = F, error=F, include=F}
action_duration <- read_csv("data/action_duration.csv") %>%
  clean_names() %>%
  dplyr::select(1:7)
advisory_and_monitoring <- read_csv("data/advisory_and_monitoring.csv") %>%
  clean_names()
beach_actions <- read_csv("data/beach_actions_(advisories_and_closures).csv") %>%
  clean_names()
beach_attributes <- read_csv("data/beach_attributes.csv") %>%
  clean_names()
beach_days <- read_csv("data/beach_days.csv") %>%
  clean_names()
beach_monitoring_frequency <- read_csv("data/beach_monitoring_frequency.csv") %>%
  clean_names()
beach_profile <- read_csv("data/beach_profile_list.csv") %>%
  clean_names()
beach_wqs_criteria_names_and_values <- read_csv("data/beach_wqs_criteria_names_and_values.csv") %>%
  clean_names()
local_action_decision_procedures <- read_csv("data/local_action_decision_procedures.csv") %>%
  clean_names()
possible_pollution_sources <- read_csv("data/possible_pollution_sources.csv") %>%
  clean_names()
tier_1_stats <- read_csv("data/tier_1_stats.csv") %>%
  clean_names()
water_quality_report <- read_csv("data/water_quality_report.csv") %>%
  clean_names()
```

```{r,include=F}
tier_1_beach_ids <- tier_1_stats$beach_id
beaches <- beach_profile %>%
  filter(beach_id %in% tier_1_beach_ids,
         year == 2020)

beaches <- stratified(beaches, 7, .5) %>%
  pull(beach_id)
```

```{r data-wrangling-q1}
ba <- beach_attributes %>%
  filter(beach_id %in% beaches) %>%
  dplyr::select(year, beach_id, beach_length_mi) %>%
  mutate(beach_length_mi = ifelse(beach_length_mi == "-", NA_character_, beach_length_mi)) %>%
  fill(beach_length_mi) %>%
  mutate(beach_length_mi = as.numeric(beach_length_mi))

bp <- beach_profile %>%
  filter(beach_id %in% beaches) %>%
  dplyr::select(year, beach_id, waterbody_name, waterbody_type, swim_status, beach_access, beach_owner) %>%
  mutate(beach_access = ifelse(beach_access == "null", NA_character_, beach_access),
         beach_owner = ifelse(beach_owner == "-", NA_character_, beach_owner),
         waterbody_name = ifelse(waterbody_name == "-", NA_character_, waterbody_name),
         waterbody_type = ifelse(waterbody_type == "-", NA_character_, waterbody_type))

watertype <-  beach_wqs_criteria_names_and_values %>%
  filter(beach_id %in% beaches) %>%
  dplyr::select(year, beach_id, water_type)

t1stats <- tier_1_stats %>%
  filter(beach_id %in% beaches) %>%
  dplyr::select(year, beach_id, no_of_days_under_beach_action, swim_season_beach_days)

risk1 <- inner_join(ba, bp)
risk2 <- inner_join(risk1, watertype)
risk <- inner_join(risk2, t1stats) %>%
  filter(no_of_days_under_beach_action < 365) %>%
  group_by(beach_id) %>%
  slice(which.max(year))
```

# Introduction
## Overview

According to he National Ocean Service, "Our oceans and coasts touch every American every day - providing us with places to live, food to eat, jobs, commerce, recreation, energy, even medicines that heal" [1]. Unfortunately, waters globally are highly vulnerable to human actions and exposed to threats such as pollution, climate change, algae blooms, coastal development, and more. In order to ensure the health of these natural environments and those who depend on them, it is essential that we understand the current status of coastal waters and which beaches are at risk for the future.

This paper will identify risk factors for the environmental degradation of beaches, which can in turn guide legislators to develop regulations regarding these bodies of water. Additionally, environmental protection of the oceans and coasts is futile without the education and engagement of the public. Public knowledge of coastal conservation is limited. According to a survey by Lotze et al., 70% of respondents believe the marine environment is under threat from human activities, but only 15% thought the ocean's health was poor or threatened [2]. By statistically analyzing data relating to the oceans and the coasts and presenting it in a way that can be understood by a general audience, this project has the ability to illustrate a clear picture of the threats to aquatic bodies in the U.S. and inform marine managers, policy makers, conservation practitioners, and educators to improve marine management and conservation programs.

In our analysis, we will look at the following research questions:

- **Measuring Risk Factors:** Can we predict the number of beach actions (beach-specific advisories or closings issued by the reporting state or local governments) based on a beach's characteristics? Similarly, are certain variables more valuable in predicting beach actions?
- **Measuring Pollution**: How are the different types of pollution (algal, animal, sewer line, etc.) distributed across U.S. waters? Are certain regions more prone to certain pollution types of pollution than others?
- **Measuring Government Communication with Locals**: How do local governments communicate with citizens when there is a beach advisory or closing? Are governments transparent in reporting the risks associated with local bodies of water to residents?

## Data

Our data were obtained through the Environmental Protection Agency (EPA) as part of their BEACON 2.0 online system [3]. The EPA created the BEach Advisory and Closing Online Notification (BEACON) to meet the Agency's requirement to provide the public a database of pollution occurrences for coastal recreational waters. Under the Beaches Environmental Assessment and Coastal Health (BEACH) Act of 2000, EPA provides annual grants to coastal and Great Lakes states, territories, and eligible tribes to help local authorities monitor their coastal and Great Lakes beaches and notify the public of water quality conditions that may be unsafe for swimming. BEACON contains state-reported beach monitoring and notification data and is fully available online without the need for special permissions.

The BEACON 2.0 online tool provides many reports on all beaches in the United States. Available datasets include those related to each action for a beach, beach attributes and profiles, beach days, beach monitoring frequency, possible pollution sources, water quality, tier 1 beach information state summaries, and more. Using BEACON 2.0's user guide found [here](https://www.epa.gov/sites/production/files/2014-08/documents/beacon_usersguide.pdf), one can view a full data dictionary, information on how to use the database, and basic summary statistics on some of the variables.

In this analysis, we will mostly focus on Tier 1 beaches, which tend to have the highest risk and the most available data across all of the datasets. States and territories designate their significant public beaches as Tier 1 beaches, which is a requirement of the BEACH Act grant program. In order to deal with issues of spatial correlation, we will take a stratified random sample of 50% of the beaches from each water body where data were available from the year 2020, which results in about 1,070 beaches in this analysis.

For our first research question on measuring risk factors, we will look at the number of days under action in a given year for each beach as the response variable. Features we would like to consider include action reason, beach ownership (private/public), beach length, water body type, beach monitoring frequency, water quality, and number of swim days. For our second research question, we will look at states, names of body waters, possible pollution sources, and water quality standards. For our third research question, we will look at local action decision procedures, which includes how governing bodies communicated beach actions with residents, and the reason/severity of the beach action. 

Additionally, we will use data from a supplemental source, "A Criteria-Based Evaluation of Environmental Literacy Plans in the United States," a dissertation by Karena Ruddiero at the University of Tennessee - Knoxville (2016) [4], which includes a dataset of all U.S. states and a score of the environmental literacy for that state based on several factors, including the integration of environmental literacy in current state curricula, graduation requirements for environmental literacy, and political status. Combining local action decision procedures for beach actions and a state's environmental literacy score will provide a more complete picture of government transparency when it comes to marine health and the public.

## Descriptive Analysis

The first two research questions revolve around predicting the number of days under action for a beach and how pollutants are distributed, respectively. In the first map below, one can see that the number of days under action vary depending on the year and region. In particular, it appears that the Gulf of Mexico and the West coast have a particularly high concentration of beaches with many days under action.  In the second map below, one can see that the number of pollutants vary over time and by region.  The most obvious observation is that from 2016 onward, it appears that the beaches of Southern California have experienced more pollution sources than in previous years. Both of these maps provide some initial insight into the state of beaches historically to present times and suggest that there may be a relationship between number of days under action and pollutants depending on the time period and region.

```{r}
us = map_data("state")

action_duration <-action_duration %>%
  filter(beach_id %in% beaches,
         no_of_days_under_action <= 365,
         no_of_days_under_action >= 0
         ) %>%
  left_join(beach_attributes, by = c("beach_id", "year")) %>%
  filter(start_latitude > 23,
         start_longitude < which.min(us$long))


beach_actions <-beach_actions %>%
  filter(beach_id %in% beaches) %>%
  left_join(beach_attributes, by = c("beach_id", "year")) %>%
  filter(start_latitude > 23,
         start_longitude < which.min(us$long)) %>%
  mutate(no_pollutants = case_when(
    action_reasons == "-" ~ NA_integer_,
    TRUE ~ lengths(strsplit(action_reasons, ", "))
  )) 
```

```{r}
a <- ggplot() +
  geom_map(data=us, map=us, aes(x=long, y=lat, map_id=region), 
           color="grey", fill=NA) +
  geom_point(data=action_duration, aes(x=as.double(start_longitude), 
                                       y=as.double(start_latitude),
                                       color=as.integer(no_of_days_under_action), 
                                       size=as.integer(no_of_days_under_action)), 
             alpha = 0.5) +
  labs(color = "Number of Days Under Action", 
       title = "West Coast and Gulf of Mexico Have Most Number of Days Under Action", 
       subtitle = "Year: {frame_time}") +
  transition_time(year) +
  scale_color_viridis(option="viridis", direction = -1, guide = guide_legend(), begin=.1) +
  ease_aes('linear')+
  scale_size(guide = FALSE) + # no legend for size
  theme_void()+
  theme(legend.position="bottom")

a_gif = animate(a, duration = 21, nframes=21)

b<- ggplot() +
  geom_map(data=us, map=us, aes(x=long, y=lat, map_id=region), 
           color="grey", fill=NA) +
  geom_point(data=beach_actions, aes(x=as.double(start_longitude), 
                                     y=as.double(start_latitude),
                                     color=as.integer(no_pollutants), 
                                     size=as.integer(no_pollutants)+2), 
             alpha = .1) +
  labs(color = "Number of Pollutants", 
       title = "Number of Pollutants Increases in California Since 2016", 
       subtitle = "Year: {frame_time}") +
  transition_time(year) +
  scale_color_viridis(option="viridis", direction = -1, guide = guide_legend(), begin=.1) +
  ease_aes('linear')+
  scale_size(guide = FALSE) + 
  theme_void()+
  theme(legend.position="bottom")

b_gif = animate(b, duration=21, nframes=21)
  
a_mgif <- image_read(a_gif)
b_mgif <- image_read(b_gif)

new_gif <- image_append(c(a_mgif[1], b_mgif[1]))
for(i in 2:21){
  combined <- image_append(c(a_mgif[i], b_mgif[i]))
  new_gif <- c(new_gif, combined)
}

new_gif
```
*Note: The size of the points in this visualization correspond to the number of beach actions or number of pollutants (the same as the color representation). This was done for ease of identification of the more extreme values.

In the following plot, one can observe the ways that local governments communicate with residents about actions which affect community beaches. This plot can provide some preliminary insight into our last research question, which revolves around the transparency of local governments in reporting news about beaches to citizens. From this plot, it appears that the most common methods of communication by local governments include posting notifications on the internet or at the beaches themselves.

```{r}
p1<- ggplot(risk, aes(x=no_of_days_under_beach_action))+
  geom_histogram(fill ="seagreen1", color="black") +
  labs(title = "Number of Days Under Beach Action\nIs Right-Skewed",
        y = "Number of Beach-Year Combinations", 
        x = "Number of Days") +
  theme_minimal()

#p1
```

```{r, fig.width=8.5, fig.height=4,fig.align='center'}
local_action_decision_procedures[local_action_decision_procedures=="-"] <- "0"
local_action_decision_procedures[local_action_decision_procedures=="Yes"] <- "1"
local_action_decision_procedures <- local_action_decision_procedures %>%
  mutate(across(9:16, as.double)) %>%
  group_by(beach_id) %>% 
  filter(year == max(year))

methods = c("Posted on Internet", "Posted at Beach", "Sent to Phone List", "Announced on TV", "Announced on Radio", "Published in Newspaper", "Results on Request", "Other")
methods_yes = c(3137,2644,1355,1204,1168,1081,236,55)
eda_methods <- cbind(methods, methods_yes) %>%
  as_tibble() %>%
  mutate(methods_yes = as.numeric(methods_yes),
         methods = fct_relevel(methods, levels = c("Other", "Results on Request", "Published in Newspaper", "Announced on Radio", "Announced on TV", "Sent to Phone List", "Posted at Beach", "Posted on Internet")))

ggplot(eda_methods, aes(x = methods, y = methods_yes)) +
  geom_bar(stat = "identity", fill = "seagreen1") +
  geom_text(aes(label=methods_yes), hjust=0)+
  coord_flip()+
  theme_minimal() +
  labs(y = "Number of Beaches", x = "Method of Communication", title = "Most Common Method of Communicating Beach Actions to Citizens\nIs via Posting on the Internet")
```

# Methodology

## Measuring Risk Factors

For this research question, the main goal is to predict the number of days under beach action for Tier 1 beaches in our random sample.  We will mainly consider features related to the physical characteristics of the beach. These features include the beach length, whether the beach is privately owned, whether the beach is accessible to the public, the water body and type of water body that the beach belongs to, the swim status of the beach, swim season length, the water type of the beach (i.e. marine or freshwater), and the number of days in the swim season. We will use the most recent observation from our random sample of Tier 1 Beaches ($n$ = 391).

Upon inspection, it appears that there are several outliers in the data, specifically, beaches where there are many days in a year under beach action. We did not think it would be wise to remove these outliers, as it is meaningful to be able to predict the number of days under beach action for these extreme cases.

Our response variable, number of days under beach action, is a discrete count which is also highly skewed right. Since over-dispersion appeared to be an issue, a Poisson model was deemed to not be ideal. However, a Negative Binomial (NB) model, which is often used instead of a Poisson model to deal with the issue of over-dispersion, appeared to be a worthy alternative.  Additionally, our outcome is zero-inflated, as confirmed by a zero inflation test on the residuals, and there is evidence of over-dispersion. To test for this, we performed an ANOVA test using AIC as the criterion to decipher whether a zero-inflated NB model or a regular NB model performed better, and the zero-inflated NB model had a lower AIC.  Therefore, in order to model the number of days under beach action, we will use a zero-inflated Negative Binomial model.

One of the assumptions with using a zero-inflated Negative Binomial model is that there should not be collinearity among the predictors. Using VIF, we were able to identify that the variables water type (i.e. freshwater, marine, both), water body type (i.e. Sound/Bay/Inlet, Still Water, Open Coast), and water body name were highly correlated. Therefore, we chose water body name, as this is the most specific of the three variables.  Another assumption is that the outcome llows a NB distribution. We created an ord plot, which helps in identifying which count data model is underlying, and obtained a positive slope and intercept, which indeed speaks for a negative binomial distribution. Upon inspection of the residual plots, specifically the QQ plot of the deviance residuals and the plot of the residuals vs. predicted appear satisfactory.

The full model specification is as follows:
(Insert model equation here)

Finally, as prediction is a goal of this analysis, we will create a test set comprised of the second most recent observation for each tier 1 beach as our test set. We will then use our model to predict the number of days under beach action for the test set, which will give us some insight into our model's predictive accuracy using metrics such as the mean square error.

## Measuring Pollution

## Measuring Government Communication with Locals

For this question, we will use a descriptive analysis approach. Our goal is to look at how governments communicate with their citizens about their beaches. To approach this question, for each state, we will find the proportion of beaches in that state which use each of the following modes of communication: posting on the internet, posting at the beach, sending to a phone list, announcing in the radio, announcing on TV, announcing on radio, providing results upon request, and other. We will only consider the most recent observation for each beach, as this probably include the most current methods of communication used by that beach. We also have information regarding the environmental literacy rating for each state.

Using this information, we will create a Shiny app. In our Shiny app, the user will be able to select which method of communication that they are interested in. Then, a plot of the Mainland USA will appear with the states filled in by proportion of beaches in that state which use that method of communication. Additionally, the user will see a point in the center of each state whose size represents the environmental literacy rating in that state.

```{r}
state_long_lat <- read_csv("data/state_long_lat.csv")
environmental_literacy <- read_csv("data/environmental_literacy.csv") %>%
  mutate(level = case_when(
    rating >= 0.5 ~ "Good",
    rating < 0.5 ~ "Poor"
  ),
  state = ifelse(state == "DC", "District of Columbia", state))

environmental_literacy <- left_join(environmental_literacy, state_long_lat, by = c("state" = "name")) %>%
  filter(!state %in% c("Hawaii", "Alaska"))

states_comms <- local_action_decision_procedures %>%
  filter(!state_code %in% c("AS", "GU", "MP", "VI")) %>%
  mutate(state_code = case_when(
    state_code %in% c("MK", "ST")~ "WA",
    state_code == "BR" ~ "WI",
    state_code == "GP" ~ "MN",
    TRUE ~ as.character(state_code))) %>%
  group_by(state_code) %>%
  summarize(prob_internet = mean(posted_on_internet), prob_newspaper = mean(published_in_newspaper),
         prob_phone = mean(sent_to_phone_l_ist), prob_radio = mean(announcedon_radio),
         prob_beach = mean(posted_atthe_beach), prob_tv = mean(announcedon_tv), 
         prob_request = mean(provided_resultson_request), prob_other = mean(other))
```

# Results
```{r, include=F}
#m_pois <- glm(no_of_days_under_beach_action ~ . -year -beach_id, risk, family = "poisson")
#summary(m_pois)
#dispersiontest(m_pois) #over-dispersion is present

m<- glm.nb(no_of_days_under_beach_action ~ . -year -beach_id-water_type-waterbody_type, risk)

m2 <- zeroinfl(no_of_days_under_beach_action ~ . -year -beach_id -water_type-waterbody_type, risk, dist="negbin")
summary(m2)
```
# Discussion

```{r, fig.align='center', include=F}
# check what the underlying count distribution is
Ord_plot(risk$no_of_days_under_beach_action)

# check which variables are significant in an ANOVA test
anova(m, test="Chisq")

# check which points are more influential
car::influencePlot(m)

# check for multicollinearity
car::vif(m)

# check if zero-inflated or non-zero-inflated model is better
AIC(m, m2)

# plot residuals
resids <- simulateResiduals(m, integerResponse=T)
plot(resids)

#outliers
outliers <- outliers(resids)

# test for zero-inflation
testZeroInflation(resids)
```

# References

- [1] [National Ocean Service](https://aambpublicoceanservice.blob.core.windows.net/oceanserviceprod/about/nos_brochure.pdf)
- [2] [Lotze et al. "Public Perceptions of Marine Threats and Protection from around the World"](http://lotzelab.biology.dal.ca/wp-content/uploads/Lotze-etal_2018_OCMA_public-perceptions.pdf)
- [3] BEACON Data Source and Information: [BEACON 2.0](https://watersgeo.epa.gov/beacon2/)
- [4] University of Tennessee - Knoxville Data Source: [Ruggiero, Karena. "A Criteria-Based Evaluation of Environmental Literacy Plans in the
United States"](https://trace.tennessee.edu/cgi/viewcontent.cgi?article=5129&context=utk_graddiss)

# Appendix